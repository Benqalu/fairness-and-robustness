{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from FaroLR import loss_robustness, loss_fairness\n",
    "from utils import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fairness(X, y, w, tp=False):\n",
    "\tif not tp:\n",
    "\t\tu_down = torch.sum(1.0 - X[:, 0])\n",
    "\t\tu_up = torch.sum(torch.sigmoid(torch.matmul(X, w)) * (1.0 - X[:, 0]))\n",
    "\t\tv_down = torch.sum(X[:, 0])\n",
    "\t\tv_up = torch.sum(torch.sigmoid(torch.matmul(X, w)) * X[:, 0])\n",
    "\t\tloss = torch.square((u_up / u_down) - (v_up / v_down))\n",
    "\telse:\n",
    "\t\ty_flat=y.reshape(-1)\n",
    "\t\tu_down = torch.sum((1.0 - X[:, 0]) * y_flat)\n",
    "\t\tu_up = torch.sum(torch.sigmoid(torch.matmul(X, w)) * (1.0 - X[:, 0]) * y_flat)\n",
    "\t\tv_down = torch.sum(X[:, 0] * y_flat)\n",
    "\t\tv_up = torch.sum(torch.sigmoid(torch.matmul(X, w)) * X[:, 0] * y_flat)\n",
    "\t\tloss = torch.square((u_up / u_down) - (v_up / v_down))\n",
    "\treturn loss\n",
    "\n",
    "def loss_robustness(X, y, w):\n",
    "\tgradx = (y.reshape(-1) - torch.sigmoid(torch.matmul(X, w))).reshape(-1, 1) * w\n",
    "\tloss = torch.mean(torch.sum(torch.square(gradx), axis=1))\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=get_data(data='adult',attr='race')\n",
    "X=np.hstack([X,np.ones(X.shape[0]).reshape(-1,1)])\n",
    "s=X[:,0]\n",
    "X=torch.tensor(X,dtype=torch.float32)\n",
    "y=torch.tensor(y,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_robustness(X,y,w):\n",
    "    w=torch.tensor(w,dtype=torch.float32,requires_grad=True)\n",
    "    loss=loss_robustness(X,y,w)\n",
    "    loss.backward()\n",
    "    return np.array(w.grad.reshape(-1).tolist())\n",
    "\n",
    "def grad_fairness(X,y,w):\n",
    "    w=torch.tensor(w,dtype=torch.float32,requires_grad=True)\n",
    "    loss=loss_fairness(X,y,w,tp=True)\n",
    "    loss.backward()\n",
    "    return np.array(w.grad.reshape(-1).tolist())\n",
    "\n",
    "sigmoid=lambda x: 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=np.random.uniform(-1,1,X.shape[1]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_torch=grad_fairness(X,y,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theoritical_grad_fairness(X,y,w):\n",
    "    X=X.numpy()\n",
    "    y=y.numpy()\n",
    "    w=np.array(w)\n",
    "    res=np.zeros(len(w))\n",
    "    \n",
    "    u=np.sum(1-X[:,0])\n",
    "    v=np.sum(X[:,0]*y)\n",
    "        r=sigmoid(np.dot(X[i],w))\n",
    "        \n",
    "    return 2*(a_up/a_down-b_up/b_down)*(c_up/c_down-d_up/d_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_plain=theoritical_grad_fairness(X,y,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haipei/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.52041075e+12,             inf, -9.23733328e+11, -2.28742414e+11,\n",
       "        2.11669620e+13,             inf,             inf,  6.61444467e+12,\n",
       "       -6.04816671e+11,             inf,             inf,  2.98893233e+12,\n",
       "       -2.24429552e+12, -2.65152692e+14, -1.48360738e+12, -1.92051479e+12,\n",
       "                   inf,             inf,            -inf,            -inf,\n",
       "       -1.73003506e+13,            -inf, -7.40134119e+12,  6.15334871e+11,\n",
       "        3.16581641e+13,             inf,             inf,             inf,\n",
       "                  -inf,             inf, -1.50644471e+12,  4.21003868e+14,\n",
       "       -2.11459165e+12,             inf,  4.21275972e+12, -4.46347608e+11,\n",
       "                   inf, -2.92419011e+11, -8.52873265e+14,  1.01687814e+12,\n",
       "                  -inf,             inf, -6.58309015e+12,            -inf,\n",
       "       -8.69889003e+12,  3.25264857e+13,            -inf,  1.31499966e+13,\n",
       "       -7.20972022e+10,             inf,  2.22532285e+12, -1.09890450e+12,\n",
       "        2.65044859e+12,  4.23362272e+12, -5.56301654e+12, -3.75895517e+12,\n",
       "                  -inf,  4.77278576e+14,             inf,  5.93453918e+13,\n",
       "        2.40547428e+14,            -inf,             inf, -1.05606485e+14,\n",
       "       -2.39068617e+13, -1.70242395e+13, -3.44543241e+13,             inf,\n",
       "        9.31966631e+13, -7.66983180e+13, -2.64698449e+14, -3.53121125e+15,\n",
       "       -6.55059822e+14,  7.85274037e+13, -1.06683847e+15,             inf,\n",
       "                   inf, -1.78469195e+14, -1.57641909e+14,  2.29967112e+14,\n",
       "       -7.08529095e+13,             inf,            -inf,             inf,\n",
       "                  -inf,  7.96024793e+13, -4.04400405e+13,             inf,\n",
       "        1.51271483e+14,             inf,             inf,             inf,\n",
       "       -1.07240082e+14,             inf,            -inf,  1.16203454e+12,\n",
       "                   inf,            -inf,             inf])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_torch/grad_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Fairness gradient is verified to be correct **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_torch=grad_robustness(X,y,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theoritical_grad_robustness(X,y,w):\n",
    "    X=X.numpy()\n",
    "    y=y.numpy()\n",
    "    w=np.array(w)\n",
    "    \n",
    "    res=np.zeros(len(w))\n",
    "    for i in range(0,X.shape[0]):\n",
    "        a=w*((y[i]-sigmoid(np.dot(w,X[i])))**2)\n",
    "        b=X[i]*np.dot(w,w)*(y[i]-sigmoid(np.dot(w,X[i])))*sigmoid(np.dot(w,X[i]))*(1.0-sigmoid(np.dot(w,X[i])))\n",
    "        res+=(a-b)\n",
    "    return 2/X.shape[0]*res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_plain=theoritical_grad_robustness(X,y,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.29230022,  0.25449067,  1.68026114,  0.41608003, -0.30080062,\n",
       "        0.21090929,  1.0546999 ,  0.37598765,  0.06875969,  1.27546751,\n",
       "        0.43849078, -0.33980227, -0.12757343, -0.11775145,  0.04216666,\n",
       "        0.10916863,  0.22497816,  0.11470972, -0.37913513, -0.18816382,\n",
       "        0.49170554, -0.12648989, -0.42071754, -0.2798219 , -0.44988957,\n",
       "        0.21373925,  0.14134668,  0.50585967, -0.39607912,  1.3355689 ,\n",
       "        0.34252587, -0.37392655, -0.96160495,  0.15492979,  1.91574132,\n",
       "       -0.02537192,  0.33506823,  0.06648839,  0.37875181,  0.23121132,\n",
       "       -0.06555521,  0.46059886, -0.37420535, -0.28880155,  0.9889493 ,\n",
       "       -0.23111458, -0.16850817,  0.37374538,  0.01639301,  0.45510548,\n",
       "       -0.12649496, -0.49972391,  1.20528448, -0.24065359,  1.26488352,\n",
       "        0.85468745, -0.542539  , -0.21195427,  0.44957766,  0.21083719,\n",
       "       -0.42729807, -0.46677196,  0.40189144, -0.1875948 ,  0.08493423,\n",
       "       -0.06048225, -0.03060159,  0.12595607, -0.16555053, -0.40873075,\n",
       "       -0.4701989 , -0.1960216 , -0.290905  , -0.06974635, -0.47377145,\n",
       "        0.48259318,  0.43991992, -0.31702498, -0.28002828, -0.40850365,\n",
       "        0.2517201 ,  0.11306837, -0.19263656,  0.04131947, -0.48498538,\n",
       "        0.14140241,  0.28734377,  0.46817774, -0.26871213,  0.37771866,\n",
       "        0.486287  ,  0.17464793,  0.19049665,  0.34030592, -0.49021024,\n",
       "        2.11372852,  0.28615564, -0.4696486 ,  2.4270463 ])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.2923016 ,  0.25449109,  1.68026082,  0.41608008, -0.30080065,\n",
       "        0.2109093 ,  1.05469989,  0.37598765,  0.06875969,  1.275468  ,\n",
       "        0.43849081, -0.33980226, -0.12757342, -0.11775145,  0.04216666,\n",
       "        0.10916868,  0.22497817,  0.11470971, -0.37913517, -0.18816384,\n",
       "        0.49170553, -0.12648989, -0.42071753, -0.27982194, -0.44988959,\n",
       "        0.21373885,  0.14134671,  0.50585971, -0.39607913,  1.33556935,\n",
       "        0.34252563, -0.37392653, -0.9616051 ,  0.15492979,  1.91574139,\n",
       "       -0.02537191,  0.33506819,  0.06648863,  0.37875181,  0.23121119,\n",
       "       -0.0655552 ,  0.46059887, -0.3742054 , -0.28880148,  0.98894926,\n",
       "       -0.23111461, -0.16850817,  0.3737454 ,  0.01639311,  0.45510548,\n",
       "       -0.12649495, -0.49972399,  1.20528415, -0.2406536 ,  1.26488377,\n",
       "        0.85468764, -0.54253904, -0.21195427,  0.44957761,  0.2108372 ,\n",
       "       -0.42729805, -0.46677195,  0.40189143, -0.1875948 ,  0.08493424,\n",
       "       -0.06048225, -0.03060159,  0.1259561 , -0.16555054, -0.40873076,\n",
       "       -0.4701989 , -0.19602161, -0.29090499, -0.06974635, -0.47377146,\n",
       "        0.48259325,  0.43991992, -0.317025  , -0.28002833, -0.40850368,\n",
       "        0.2517201 ,  0.11306837, -0.19263656,  0.04131947, -0.48498538,\n",
       "        0.14140243,  0.28734379,  0.46817776, -0.26871215,  0.37771867,\n",
       "        0.48628703,  0.17464793,  0.19049667,  0.34030594, -0.49021025,\n",
       "        2.11372996,  0.28615565, -0.46964864,  2.4270463 ])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9999994 , 0.99999837, 1.00000019, 0.99999988, 0.99999992,\n",
       "       0.99999996, 1.00000001, 1.        , 1.0000001 , 0.99999962,\n",
       "       0.99999992, 1.00000001, 1.00000006, 1.00000003, 0.99999987,\n",
       "       0.9999995 , 0.99999995, 1.00000006, 0.99999991, 0.99999987,\n",
       "       1.00000001, 1.00000003, 1.00000003, 0.99999987, 0.99999996,\n",
       "       1.00000185, 0.99999976, 0.99999992, 0.99999997, 0.99999966,\n",
       "       1.00000069, 1.00000005, 0.99999984, 0.99999998, 0.99999997,\n",
       "       1.00000062, 1.0000001 , 0.9999963 , 1.00000001, 1.00000058,\n",
       "       1.00000017, 0.99999998, 0.99999986, 1.00000024, 1.00000004,\n",
       "       0.99999989, 1.00000002, 0.99999995, 0.99999353, 1.00000001,\n",
       "       1.00000011, 0.99999984, 1.00000027, 0.99999995, 0.9999998 ,\n",
       "       0.99999978, 0.99999993, 0.99999997, 1.00000011, 0.99999991,\n",
       "       1.00000004, 1.00000002, 1.00000003, 0.99999999, 0.99999993,\n",
       "       0.99999995, 0.99999993, 0.99999982, 0.99999993, 0.99999998,\n",
       "       1.        , 0.99999997, 1.00000003, 0.99999994, 0.99999999,\n",
       "       0.99999986, 1.        , 0.99999994, 0.99999982, 0.99999994,\n",
       "       1.        , 0.99999999, 1.00000001, 1.00000002, 1.        ,\n",
       "       0.99999986, 0.99999994, 0.99999995, 0.99999995, 0.99999997,\n",
       "       0.99999992, 1.00000001, 0.99999991, 0.99999997, 0.99999997,\n",
       "       0.99999932, 0.99999998, 0.99999992, 1.        ])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_torch/grad_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Robustness gradient is verified to be correct **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
