

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Matlab Wrappers for AdversariaLib (with Examples) &mdash; AdversariaLib 1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="AdversariaLib 1.0 documentation" href="index.html" />
    <link rel="prev" title="AdversariaLib’s documentation" href="advlib.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="advlib.html" title="AdversariaLib’s documentation"
             accesskey="P">previous</a> |</li>
        <li><a href="advlib.html">AdversariaLib 1.0 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="matlab-wrappers-for-adversarialib-with-examples">
<h1>Matlab Wrappers for AdversariaLib (with Examples)<a class="headerlink" href="#matlab-wrappers-for-adversarialib-with-examples" title="Permalink to this headline">¶</a></h1>
<dl class="docutils">
<dt>Contents:</dt>
<dd><ul class="first simple">
<li><a class="reference internal" href="#outline">Outline</a></li>
<li><a class="reference internal" href="#requirements">Requirements</a></li>
<li><a class="reference internal" href="#experiments">Experiments</a></li>
<li><a class="reference internal" href="#getting-help">Getting Help</a></li>
</ul>
<p class="last"><tt class="docutils literal"><span class="pre">Authors:</span></tt> <a class="reference external" href="http://pralab.diee.unica.it/en/IginoCorona">Igino Corona</a>, <a class="reference external" href="http://pralab.diee.unica.it/en/BattistaBiggio">Battista Biggio</a>, <a class="reference external" href="http://pralab.diee.unica.it/en/DavideMaiorca">Davide Maiorca</a>, Pattern Recognition and Applications Lab, Dept. of Electrical and Electronic Engineering, University of Cagliari, Italy.</p>
</dd>
</dl>
<div class="section" id="outline">
<span id="id1"></span><h2>Outline<a class="headerlink" href="#outline" title="Permalink to this headline">¶</a></h2>
<p>In security-sensitive applications, the success of machine learning depends on a thorough vetting of their resistance to adversarial data. In one pertinent, well-motivated attack scenario, an adversary may attempt to evade a deployed system at test time by carefully manipulating attack samples. In this work, we present a simple but effective gradient-based approach that can be exploited to systematically assess the security of several, widely-used classification algorithms against evasion attacks.</p>
<p>Following a recently proposed framework for security evaluation, we simulate attack scenarios that exhibit different risk levels for the classifier by increasing the attacker&#8217;s knowledge of the system and her ability to manipulate attack samples. This gives the classifier designer a better picture of the classifier performance under evasion attacks, and allows him to perform a more informed model selection (or parameter setting). We evaluate our approach on the relevant security task of malware detection in PDF files, and show that such systems can be easily evaded. We also sketch some countermeasures suggested by our analysis.</p>
<p id="paper"><tt class="docutils literal"><span class="pre">Full</span> <span class="pre">paper</span></tt>: Biggio B., Corona I., Maiorca D., Nelson B., Srndic N., Laskov P., Giacinto G., Roli F., <a class="reference download internal" href="_downloads/Biggio13-ecml.pdf"><tt class="xref download docutils literal"><span class="pre">Evasion</span> <span class="pre">attacks</span> <span class="pre">against</span> <span class="pre">machine</span> <span class="pre">learning</span> <span class="pre">at</span> <span class="pre">test</span> <span class="pre">time</span></tt></a>, in <a class="reference external" href="http://www.ecmlpkdd2013.org">European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases* (ECML-PKDD 2013)</a>, Prague, Czech Republic, 2013.</p>
<p>In the following we describe how to replicate the experiments described in the above research paper. We also describe how to customize or create new experiments for other &#8220;adversarial&#8221; evaluations, through a rich set of examples (to this end, please visit also the <a class="reference external" href="advlib.html">adversariaLib</a> page). This document is released together with our <strong>open-source</strong> library <a class="reference external" href="advlib.html">adversariaLib</a>: a general-purpose library for the security evaluation of machine learning algorithms, which has been used for the experimental evaluation of the attacks described in the paper. Thus, our aim is not only allowing other researchers to replicate the experiments in our <a class="reference internal" href="#paper">paper</a>
but also:</p>
<ul class="simple">
<li>allowing other researchers to evaluate the proposed gradient-descent attack with other datasets, experimental settings, and classifiers;</li>
<li>allowing other researchers to build on (and contribute to) our library for the evaluation of machine learning algorithms against adversarial attacks.</li>
</ul>
</div>
<div class="section" id="requirements">
<span id="id2"></span><h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h2>
<p>In order to replicate the experiments described in the <a class="reference internal" href="#paper">paper</a>, it is necessary to:</p>
<ul>
<li><p class="first">install <a class="reference external" href="http://www.mathworks.it">Matlab</a>: we experimented with the version <em>R2012</em> and higher.</p>
<blockquote>
<div><ul>
<li><p class="first">We found a problem when using <a class="reference external" href="http://www.mathworks.it">Matlab</a> on <a class="reference external" href="http://releases.ubuntu.com/raring/">Ubuntu 13.04</a> for 64bit architectures (that may also occur for 32bit arch.). In particular, the <tt class="docutils literal"><span class="pre">library</span> <span class="pre">libgfortran.so.3</span></tt> is not properly loaded from <a class="reference external" href="http://www.mathworks.it">Matlab</a>. Here&#8217;s the solution.</p>
<blockquote>
<div><ul>
<li><dl class="first docutils">
<dt>Locate the Matlab&#8217;s dynamic library <tt class="docutils literal"><span class="pre">libgfortran.so.3</span></tt>:</dt>
<dd><div class="first last highlight-python"><pre>$ locate libgfortran
/home/MATLAB/R2013a/sys/os/glnxa64/libgfortran.so.3
/home/MATLAB/R2013a/sys/os/glnxa64/libgfortran.so.3.0.0</pre>
</div>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Look at the files related to the <tt class="docutils literal"><span class="pre">libgfortran</span></tt> package:</dt>
<dd><div class="first last highlight-python"><pre>$ dpkg-query -L libgfortran3
/.
/usr
/usr/share
/usr/share/doc
/usr/lib
/usr/lib/x86_64-linux-gnu
/usr/lib/x86_64-linux-gnu/libgfortran.so.3.0.0
/usr/share/doc/libgfortran3
/usr/lib/x86_64-linux-gnu/libgfortran.so.3</pre>
</div>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Override the Matlab&#8217;s dynamic library:</dt>
<dd><div class="first highlight-python"><pre>$ sudo ln -sf /usr/lib/x86_64-linux-gnu/libgfortran.so.3 /home/MATLAB/R2013a/sys/os/glnxa64/libgfortran.so.3</pre>
</div>
<p class="last"><strong>NOTE</strong>: <em>replace</em> the first and the second path with the ones found in your case!</p>
</dd>
</dl>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">download the <a class="reference external" href="https://sourceforge.net/projects/adversarialib/files/adversariaLib_plus_matlab_code.zip/download">whole package containing both adversariaLib and all Matlab code employed for our experiments</a>.</p>
</li>
<li><p class="first">follow all steps described in the <a class="reference external" href="advlib.html#installation">installation section of adversariaLib</a></p>
</li>
</ul>
</div>
<div class="section" id="experiments">
<span id="id3"></span><h2>Experiments<a class="headerlink" href="#experiments" title="Permalink to this headline">¶</a></h2>
<div class="section" id="sample-experiment">
<h3>Sample Experiment<a class="headerlink" href="#sample-experiment" title="Permalink to this headline">¶</a></h3>
<p>We firstly provide a simple experiment that is useful for testing purposes. Simply open the file <tt class="docutils literal"><span class="pre">main.m</span></tt> (within the <tt class="docutils literal"><span class="pre">matlab</span></tt> folder) and run the script. It will launch the experiment defined inside the <tt class="docutils literal"><span class="pre">exp_example</span></tt> folder, i.e., a gradient descent attack against Support Vector machines (both linear and with RBF kernel) and Multi-Layer Perceptron (aka Artificial Neural Network) with a single output and hidden layer. The dataset is the same used for our evaluation on a real PDF malware detector, described in the <a class="reference internal" href="#paper">paper</a>. In particular, both perfect (PK) and limited knowledge (LK) settings are evaluated.</p>
<p>The output of the experiment consists of a single plot (check out the <tt class="docutils literal"><span class="pre">exp1/fig</span></tt> folder) where, for each classifier, we display how the False Negative (FN) rate changes with the increasing of <img class="math" src="_images/math/3f0f7d59e6a000e3b2e57a3cf96d612f9290505b.png" alt="d_{max}"/>, i.e., the maximum number of PDF <em>name objects</em> that can be added to a malicious PDF document:</p>
<img alt="_images/plot.png" class="align-center" src="_images/plot.png" />
<p><strong>NOTE</strong>: Make sure that the path of the <tt class="docutils literal"><span class="pre">python</span></tt> interpreter and the <tt class="docutils literal"><span class="pre">pyfann</span></tt> library are set correctly. You can set them by operating on the <tt class="xref py py-func docutils literal"><span class="pre">setenv()</span></tt> function inside <tt class="docutils literal"><span class="pre">main.m</span></tt>. AdversariaLib is multi-processing enabled. If you want more threads to be executed, you can change the
<tt class="docutils literal"><span class="pre">exp_params.threads</span></tt> value within the configuration file and set it accordingly to the number of processes to be used concurrently. If you use <tt class="docutils literal"><span class="pre">-1</span></tt>, all CPUs will be used for the computations.</p>
</div>
<div class="section" id="replicating-the-experiments-in-the-paper">
<h3>Replicating the experiments in the <a class="reference internal" href="#paper">paper</a><a class="headerlink" href="#replicating-the-experiments-in-the-paper" title="Permalink to this headline">¶</a></h3>
<div class="section" id="gradient-descent-attack-simulation-on-an-artificial-dataset-composed-by-bi-dimensional-patterns">
<h4>Gradient Descent Attack simulation on an Artificial dataset composed by bi-dimensional patterns<a class="headerlink" href="#gradient-descent-attack-simulation-on-an-artificial-dataset-composed-by-bi-dimensional-patterns" title="Permalink to this headline">¶</a></h4>
<p>The  <tt class="docutils literal"><span class="pre">matlab-examples/main_2d.m</span></tt> script provides the <a class="reference external" href="http://www.mathworks.it">Matlab</a> code for replicating the experiment on an Artificial dataset composed by bi-dimensional patterns reported in our <a class="reference internal" href="#paper">paper</a>. In order to run this simulation:</p>
<ul class="simple">
<li>follow all steps described in the <a class="reference external" href="advlib.html#installation">installation section of adversariaLib</a></li>
<li>simply run the script <tt class="docutils literal"><span class="pre">main_2d.m</span></tt> with <a class="reference external" href="http://www.mathworks.it">Matlab</a>.</li>
</ul>
<p>The MATLAB code produces 2D plots similar to those reported in Fig.1 of our <a class="reference internal" href="#paper">paper</a>:</p>
<img alt="_images/SVM_rbf-0.png" class="align-center" src="_images/SVM_rbf-0.png" />
<img alt="_images/SVM_rbf-5.png" class="align-center" src="_images/SVM_rbf-5.png" />
<img alt="_images/SVM_rbf-20.png" class="align-center" src="_images/SVM_rbf-20.png" />
</div>
<div class="section" id="gradient-descent-attack-simulation-on-a-toy-example-based-on-the-mnist-database-of-handwritten-digits">
<h4>Gradient Descent Attack simulation on a Toy example based on the <a class="reference external" href="http://yann.lecun.com/exdb/mnist/">MNIST Database of Handwritten Digits</a><a class="headerlink" href="#gradient-descent-attack-simulation-on-a-toy-example-based-on-the-mnist-database-of-handwritten-digits" title="Permalink to this headline">¶</a></h4>
<p>The  <tt class="docutils literal"><span class="pre">matlab-examples/main_mnist.m</span></tt> script provides the <a class="reference external" href="http://www.mathworks.it">Matlab</a> code (and data) for replicating the toy experiment on the <a class="reference external" href="http://yann.lecun.com/exdb/mnist/">MNIST Database of Handwritten Digits</a> reported in our <a class="reference internal" href="#paper">paper</a>.
In order to run this simulation:</p>
<ul class="simple">
<li>follow all steps described in the <a class="reference external" href="advlib.html#installation">installation section of adversariaLib</a></li>
<li>simply run the script <tt class="docutils literal"><span class="pre">main_mnist.m</span></tt> with <a class="reference external" href="http://www.mathworks.it">Matlab</a>.</li>
</ul>
<p>A plot showing the effect of a Gradient Descent Attack on a Handwritten Digits Recognition system will be generated:</p>
<img alt="_images/digits.png" class="align-center" src="_images/digits.png" />
</div>
<div class="section" id="gradient-descent-attack-against-a-real-pdf-malware-detector">
<h4>Gradient Descent Attack against a real PDF Malware Detector<a class="headerlink" href="#gradient-descent-attack-against-a-real-pdf-malware-detector" title="Permalink to this headline">¶</a></h4>
<p>Simply open <tt class="docutils literal"><span class="pre">main.m</span></tt> within the <tt class="docutils literal"><span class="pre">matlab</span></tt> folder, and set <tt class="docutils literal"><span class="pre">setup_folder</span> <span class="pre">=</span> <span class="pre">&quot;exp_paper_ecml&quot;</span></tt>. Run the script. If you set <tt class="docutils literal"><span class="pre">make_exp</span> <span class="pre">=</span> <span class="pre">1</span></tt>, the whole experiment  will be executed and the results will be saved in the <tt class="docutils literal"><span class="pre">results</span></tt> folder, inside each <tt class="docutils literal"><span class="pre">exp</span></tt> folder within the <tt class="docutils literal"><span class="pre">exp_paper_ecml</span></tt> folder. If you have already perfomed the <tt class="docutils literal"><span class="pre">exp_paper_ecml</span></tt> experiment, you can set <tt class="docutils literal"><span class="pre">make_plots</span> <span class="pre">=</span> <span class="pre">1</span></tt> to display the plots. They will be saved within the <tt class="docutils literal"><span class="pre">fig</span></tt> folder within each <tt class="docutils literal"><span class="pre">exp</span></tt> folder of the experiment.</p>
<p>Experiments can be also executed in background with <tt class="docutils literal"><span class="pre">make_exp</span> <span class="pre">=</span> <span class="pre">1</span></tt> and <tt class="docutils literal"><span class="pre">make_plots</span> <span class="pre">=</span> <span class="pre">0</span></tt>, through the shell command:</p>
<div class="highlight-python"><pre>$ nohup matlab &lt; main.m &gt; output.txt &amp;</pre>
</div>
</div>
<div class="section" id="our-results">
<h4>Our results<a class="headerlink" href="#our-results" title="Permalink to this headline">¶</a></h4>
<p>We also provide our computed results as a compressed archive <tt class="docutils literal"><span class="pre">exp_paper.tar.gz</span></tt>. You may just rename or remove the current <tt class="docutils literal"><span class="pre">exp_paper_ecml</span></tt> folder, and uncompress the archive. It will create again the folder &#8216;exp_paper_ecml&#8217;, including the results of our experiments.
Therefore, you may just set <tt class="docutils literal"><span class="pre">make_exp</span> <span class="pre">=</span> <span class="pre">0</span></tt> and leave <tt class="docutils literal"><span class="pre">make_plots</span> <span class="pre">=</span> <span class="pre">1</span></tt> to generate the corresponding plots.</p>
<p>We tested our <a class="reference external" href="http://www.mathworks.it">Matlab</a>/<a class="reference external" href="advlib.html">adversariaLib</a> scripts on <a class="reference external" href="http://www.apple.com/it/osx/">Apple Mac OS X 10.8.4</a> and <a class="reference external" href="http://releases.ubuntu.com/raring/">Ubuntu 13.04</a> (64 bits).</p>
</div>
</div>
</div>
<div class="section" id="defining-new-experiments">
<h2>Defining new Experiments<a class="headerlink" href="#defining-new-experiments" title="Permalink to this headline">¶</a></h2>
<div class="section" id="general-instructions">
<h3>General Instructions<a class="headerlink" href="#general-instructions" title="Permalink to this headline">¶</a></h3>
<ol class="arabic simple">
<li>Inside the matlab folder, create a folder dedicated to the new experiment (e.g., <tt class="docutils literal"><span class="pre">expfolder</span></tt>).</li>
<li>Inside the setup folder, <em>for each figure</em> that you want to print, you have to create a folder whose name starts with &#8220;exp&#8221;.</li>
<li>You have to put one or more configuration files inside each &#8220;exp&#8221; folder, depending on how many curves you want to trace on the figure. You can use <tt class="docutils literal"><span class="pre">set_params_example.m</span></tt> as a template for each new experimental setting. <strong>NOTE</strong>: Each configuration file must start with &#8220;set&#8221; (e.g., <tt class="docutils literal"><span class="pre">set_params_svm_lin_lambda_0.m</span></tt>).</li>
<li>Open <tt class="docutils literal"><span class="pre">main.m</span></tt> inside the <tt class="docutils literal"><span class="pre">matlab</span></tt> folder. Set <tt class="docutils literal"><span class="pre">setup_folder</span> <span class="pre">=</span> <span class="pre">&quot;expfolder&quot;</span></tt>.</li>
<li>Set the <tt class="docutils literal"><span class="pre">flag</span> <span class="pre">make_exp</span> <span class="pre">=</span> <span class="pre">1</span></tt> (if you want to run the experiment using python) and make_plots = 1 (if you want Matlab to show plots).</li>
<li>Run <tt class="docutils literal"><span class="pre">main.m</span></tt>!</li>
<li>For each &#8220;exp&#8221; folder, you will find the plots inside the <tt class="docutils literal"><span class="pre">fig</span></tt> folder, in PDF/EPS format: <tt class="docutils literal"><span class="pre">plot.&lt;pdf|eps&gt;</span></tt>.</li>
</ol>
</div>
<div class="section" id="understanding-experimental-setups-for-new-experiments">
<h3>Understanding experimental setups for new experiments<a class="headerlink" href="#understanding-experimental-setups-for-new-experiments" title="Permalink to this headline">¶</a></h3>
<p>Each experiment is defined through a file whose name has the following format: <tt class="docutils literal"><span class="pre">set_params_xxx.m</span></tt>. Each file is used to generate a <tt class="docutils literal"><span class="pre">setup.py</span></tt> file according to the <a class="reference external" href="advlib.html">adversariaLib</a> syntax. In the following we report the contents of <tt class="docutils literal"><span class="pre">set_params_example.m</span></tt>, that can be considered as a matlab template for the definition of new experiments:</p>
<div class="highlight-python"><pre>exp_params.dataset_name = 'norm_pdf_med';
exp_params.test_fraction = 0.1; %fraction of randomly chosen test data (the rest will be used for training)
exp_params.nfolds = 3; %number of folds for cross validation
exp_params.nsplits = 1; %number of splits
exp_params.threads = 1; %number of threads (note: if you set -1 it will use all the processors)
exp_params.norm_weights = 'norm_weights.txt'; %normalization parameters for the PDF data.
exp_params.fig_folder = 'fig'; %in this folder (inside each experiment folder) the plot will be saved
exp_params.code_folder = '../adversariaLib'; % This is the relative path to the adversarialib code folder
exp_params.dataset_folder = '../../../../../dataset'; %This is the folder in which the dataset is stored


classifier_params.classifier = 'SVM_lin'; % 'SVM_rbf' or 'MLP'
classifier_params.xval=0;
classifier_params.mlp_steepness = 0.0005;
classifier_params.neurons = 5;
classifier_params.svm_C = 1;
classifier_params.svm_gamma = 1;

evil_classifier_params.training_size = 100;
evil_classifier_params.num_rep = 1; %Number of classifier's copies to learn by randomly sampling a training set
evil_classifier_params.classifier = classifier_params.classifier;
evil_classifier_params.xval= classifier_params.xval;
evil_classifier_params.mlp_steepness = classifier_params.mlp_steepness;
evil_classifier_params.neurons = classifier_params.neurons;
evil_classifier_params.svm_C = classifier_params.svm_C;
evil_classifier_params.svm_gamma = classifier_params.svm_gamma;

mimicry_params.mimicry_distance = 'kde_hamming';
mimicry_params.lambda = 0;
mimicry_params.kde_gamma = 0.1;
mimicry_params.max_leg_patterns = 100;

constraint_params.constraint = 'only_increment'; %Choose between: box, hamming, only_increment
constraint_params.constraint_step = 5;
constraint_params.max_boundaries = 10;

plot_params.title=['SVM (Linear)' ...
        ', \lambda=' num2str(mimicry_params.lambda)]; %Set up plot title
plot_params.legend_lk = ['SVM LIN' '- LK' ' (C=' num2str(classifier_params.neurons) ')']; %Set up legend for lk
plot_params.legend_pk = ['SVM LIN' '- PK' ' (C=' num2str(classifier_params.neurons) ')']; %Set up legend for pk
plot_params.color = 'r';

gradient_params.grad_step = 0.01;</pre>
</div>
<p>Please note that almost all parameters are associated to parameters of a <a class="reference external" href="advlib.html">adversariaLib</a> <tt class="docutils literal"><span class="pre">setup.py</span></tt> file (the parameters of <em>surrogate</em> classifiers are defined through the <tt class="docutils literal"><span class="pre">evil_classifier_params</span></tt> structure). The unique matlab-dependent parameters are as follows:</p>
<div class="highlight-python"><pre>exp_params.fig_folder = 'fig';
exp_params.code_folder = '../adversariaLib';
plot_params.title=['SVM (Linear)' ...
        ', \lambda=' num2str(mimicry_params.lambda)]; %Set up plot title
plot_params.legend_lk = ['SVM LIN' '- LK' ' (C=' num2str(classifier_params.neurons) ')']; %Set up legend for lk
plot_params.legend_pk = ['SVM LIN' '- PK' ' (C=' num2str(classifier_params.neurons) ')']; %Set up legend for pk
plot_params.color = 'r';</pre>
</div>
<p>Here follows a description of each one of the above settings:</p>
<ul>
<li><p class="first"><tt class="docutils literal"><span class="pre">exp_params.fig_folder</span></tt> sets the default folder for the figures of an experiment;</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">exp_params.code_folder</span></tt> relative path to the <tt class="docutils literal"><span class="pre">adversariaLib</span></tt> code;</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">classifier_params.xval</span></tt> tells the matlab script for the generation of <tt class="docutils literal"><span class="pre">adversariaLib</span></tt> setups to use (if <tt class="docutils literal"><span class="pre">1</span></tt>) or not (if <tt class="docutils literal"><span class="pre">0</span></tt>) cross-validation for finding the best classifier&#8217;s parameters. In particular, if <tt class="docutils literal"><span class="pre">classifier_params.xval</span> <span class="pre">=</span> <span class="pre">1</span></tt>, here are the default <tt class="docutils literal"><span class="pre">adversariaLib</span></tt> settings:</p>
<blockquote>
<div><ul class="simple">
<li>for <em>linear SVMs</em>: <tt class="docutils literal"><span class="pre">'grid_search':</span> <span class="pre">{'param_grid':</span> <span class="pre">dict(C=np.logspace(-3,</span> <span class="pre">2,</span> <span class="pre">6))}</span></tt></li>
<li>for <em>RBF kernel SVMs</em>: <tt class="docutils literal"><span class="pre">'grid_search':</span> <span class="pre">{'param_grid':</span> <span class="pre">dict(C=np.logspace(-3,</span> <span class="pre">2,</span> <span class="pre">6),</span> <span class="pre">gamma=np.logspace(-3,</span> <span class="pre">3,</span> <span class="pre">7))}</span></tt></li>
</ul>
<p>such settings can be changed in the Matlab script <tt class="docutils literal"><span class="pre">utils/setup_write_classifier_params.m</span></tt>.</p>
</div></blockquote>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">plot_params.title</span></tt> sets the title of the plot; in this case, classifier type and lambda parameter are displayed;</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">plot_params.legend_lk</span></tt> sets the legend of the (solid) curve related to Limited Knowledge (LK);</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">plot_params.legend_pk</span></tt> sets the legend of the (dashed) curve related to Perfect Knowledge (PK);</p>
</li>
<li><p class="first"><tt class="docutils literal"><span class="pre">plot_params.color</span></tt> sets the color of the curve.</p>
</li>
</ul>
</div>
</div>
<div class="section" id="getting-help">
<span id="id4"></span><h2>Getting Help<a class="headerlink" href="#getting-help" title="Permalink to this headline">¶</a></h2>
<p>Please use the <a class="reference external" href="https://sourceforge.net/p/adversarialib/discussion/?source=navbar">forum on the official repository of adversariaLib</a>.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="advlib.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Matlab Wrappers for AdversariaLib (with Examples)</a><ul>
<li><a class="reference internal" href="#outline">Outline</a></li>
<li><a class="reference internal" href="#requirements">Requirements</a></li>
<li><a class="reference internal" href="#experiments">Experiments</a><ul>
<li><a class="reference internal" href="#sample-experiment">Sample Experiment</a></li>
<li><a class="reference internal" href="#replicating-the-experiments-in-the-paper">Replicating the experiments in the paper</a><ul>
<li><a class="reference internal" href="#gradient-descent-attack-simulation-on-an-artificial-dataset-composed-by-bi-dimensional-patterns">Gradient Descent Attack simulation on an Artificial dataset composed by bi-dimensional patterns</a></li>
<li><a class="reference internal" href="#gradient-descent-attack-simulation-on-a-toy-example-based-on-the-mnist-database-of-handwritten-digits">Gradient Descent Attack simulation on a Toy example based on the MNIST Database of Handwritten Digits</a></li>
<li><a class="reference internal" href="#gradient-descent-attack-against-a-real-pdf-malware-detector">Gradient Descent Attack against a real PDF Malware Detector</a></li>
<li><a class="reference internal" href="#our-results">Our results</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#defining-new-experiments">Defining new Experiments</a><ul>
<li><a class="reference internal" href="#general-instructions">General Instructions</a></li>
<li><a class="reference internal" href="#understanding-experimental-setups-for-new-experiments">Understanding experimental setups for new experiments</a></li>
</ul>
</li>
<li><a class="reference internal" href="#getting-help">Getting Help</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="advlib.html"
                        title="previous chapter">AdversariaLib&#8217;s documentation</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/matlab.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="advlib.html" title="AdversariaLib’s documentation"
             >previous</a> |</li>
        <li><a href="advlib.html">AdversariaLib 1.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2014, Igino Corona, Battista Biggio, Davide Maiorca.
    </div>
  </body>
</html>